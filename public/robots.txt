# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To allow all robots to crawl your site, use the following line:
# User-agent: *
# Disallow:
#
# To disallow all robots from crawling your site, use the following line:
# User-agent: *
# Disallow: /
#
# To only allow specific robots to crawl your site, use the following lines:
# User-agent: Googlebot
# Disallow:
#
# User-agent: *
# Disallow: /

User-agent: *
Disallow:

Sitemap: https://www.your-gastronomic-hub.com/sitemap.xml
